# Ollama Configuration
ollama.api.base.url=http://localhost:11434
ollama.api.timeout.seconds=30
ollama.api.max.retries=3
ollama.api.retry.delay.ms=1000

# Default Model Configuration
ollama.default.model=llama2
ollama.default.temperature=0.7
ollama.default.max.tokens=2048
ollama.default.top.p=0.9
ollama.default.top_k=40

# AI Enhancement Settings
ollama.ai.enabled=true
ollama.ai.strategy.enhancement=true
ollama.ai.behavior.learning=true
ollama.ai.tactical.analysis=true
ollama.ai.difficulty.scaling=true

# Performance Settings
ollama.cache.enabled=true
ollama.cache.size=1000
ollama.cache.ttl.minutes=60
ollama.async.enabled=true
ollama.async.thread.pool.size=4

# Logging and Monitoring
ollama.logging.enabled=true
ollama.metrics.enabled=true
ollama.debug.mode=false


